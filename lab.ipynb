{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import build_data_loader_train_detection, denormalize_transform\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = build_data_loader_train_detection( \n",
    "    'dataset_detection_pre', \n",
    "    batch_size = 4, \n",
    "    max_objects = 200, \n",
    "    max_poly_points = 64, \n",
    "    crop_size = 640, \n",
    "    mode = 'seg' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = iter( data_loader )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage, ToTensor\n",
    "from PIL import ImageDraw\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "def draww(data, grid_cols=4):\n",
    "    \"\"\"\n",
    "    Randomly samples num_samples items from the dataset, draws bounding boxes and polygons,\n",
    "    and returns (and optionally saves) a grid image of the results.\n",
    "    \n",
    "    Args:\n",
    "        dataset (Dataset): Your DeficiencyDataset instance.\n",
    "        num_samples (int): Total number of samples to draw (should equal grid_rows * grid_cols).\n",
    "        grid_cols (int): Number of columns in the grid.\n",
    "        output_path (str, optional): If provided, the grid image will be saved to this path.\n",
    "        \n",
    "    Returns:\n",
    "        grid_img (PIL.Image): The resulting grid image with drawn annotations.\n",
    "    \"\"\"\n",
    "    # We'll use ToPILImage to convert tensor images (if needed)\n",
    "    to_pil = ToPILImage()\n",
    "    to_tensor = ToTensor()\n",
    "\n",
    "    drawn_images = []\n",
    "    # Randomly select indices from the dataset.\n",
    "    poligons_shapes = []\n",
    "    sample_localizations1 = []\n",
    "    sample_localizations2 = []\n",
    "    sample_localizations3 = []\n",
    "    size = len( data[0] )\n",
    "    for i in range( size ):\n",
    "\n",
    "        # img = denormalize_transform( data[0][i] )\n",
    "        img = data[0][i]\n",
    "        labels = data[1][i]\n",
    "        bounding_boxes = data[2][i]\n",
    "        polygons = data[3][i]\n",
    "\n",
    "        sample_localizations1.append( data[4][0][i] )\n",
    "        sample_localizations2.append( data[4][1][i] )\n",
    "        sample_localizations3.append( data[4][2][i] )\n",
    "        \n",
    "        # If the image is a tensor, convert it to a PIL image.\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            # Assume image tensor is in [C,H,W] format.\n",
    "            img = to_pil( img )\n",
    "        \n",
    "        # Create a drawing context.\n",
    "        draw = ImageDraw.Draw( img )\n",
    "\n",
    "        # The crop size is assumed to be the image size.\n",
    "        crop_w, crop_h = img.size\n",
    "        for label, bbox, polygon in zip( labels, bounding_boxes, polygons ):\n",
    "\n",
    "            if label == 0:\n",
    "                continue\n",
    "            \n",
    "            unormalized_coords = np.array( [ ( x * crop_w, y * crop_h ) for x, y in polygon ] )\n",
    "\n",
    "            poligons_shapes.append( unormalized_coords.shape )\n",
    "            \n",
    "            # Convert normalized bbox to absolute coordinates.\n",
    "            x_min = bbox[0] * crop_w\n",
    "            y_min = bbox[1] * crop_h\n",
    "            x_max = ( bbox[0] + bbox[2] ) * crop_w\n",
    "            y_max = ( bbox[1] + bbox[3] ) * crop_h\n",
    "            \n",
    "            # Draw bounding box.\n",
    "            draw.rectangle( [ x_min, y_min, x_max, y_max ], outline = \"red\", width = 2 )\n",
    "                        \n",
    "            # Draw polygon if available.\n",
    "            if unormalized_coords is not None and unormalized_coords.shape[0] >= 3:\n",
    "                # polygon_np is expected in OpenCV format: shape [1, num_points, 2].\n",
    "                poly_points = [ tuple(pt) for pt in unormalized_coords ]\n",
    "                draw.line( poly_points + [ poly_points[0] ], fill = \"blue\", width = 2 )\n",
    "\n",
    "        # Append the drawn image.\n",
    "        drawn_images.append(to_tensor(img))\n",
    "    \n",
    "    # Create a grid of images.\n",
    "    grid = make_grid(drawn_images, nrow=grid_cols, padding=4)\n",
    "    grid_img = to_pil(grid)\n",
    "    \n",
    "    return grid_img, np.unique( poligons_shapes ), ( sample_localizations1, sample_localizations2, sample_localizations3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def resize_image(image_tensor, size):\n",
    "    return F.interpolate( image_tensor.unsqueeze(0), size = ( size, size ),\n",
    "                          mode = 'bilinear', align_corners = False ).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next( idata )\n",
    "drawn_img, poligons_shapes, locs = draww(data, grid_cols=2)\n",
    "print( f\"Unique polygon shapes: {poligons_shapes}\" )\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(drawn_img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for sample in range(len(data[0])):    \n",
    "    img = []\n",
    "    for m in locs:\n",
    "        mask = m[sample]\n",
    "        image = data[0][sample]\n",
    "        im_size = image.shape[1]\n",
    "        mask_size = mask.shape[1]\n",
    "        random_mask_color = torch.zeros_like( image )\n",
    "        random_mask_color += torch.rand( 3 )[:,None,None]\n",
    "        mask = resize_image( mask[None], im_size )\n",
    "        image = ( mask * denormalize_transform( image ) ) + ( ( 1 - mask ) *  random_mask_color)\n",
    "        img.append( image )\n",
    "    images.append( torch.cat( img, dim = 2 ) )\n",
    "grid = torch.cat( images, dim = 1 )\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.imshow(grid.permute(1, 2, 0))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc: int = 25\n",
    "ch: tuple = (384, 384, 384)\n",
    "hd: int = 256  # hidden dim\n",
    "nq: int = 300  # num queries\n",
    "ndp: int = 4  # num decoder points\n",
    "nh: int = 8  # num head\n",
    "ndl: int = 6  # num decoder layers\n",
    "d_ffn: int =   # dim of feedforward\n",
    "dropout: float = 0.0\n",
    "act: nn.Module = nn.ReLU()\n",
    "eval_idx: int = -1\n",
    "# Training args\n",
    "learnt_init_query: bool = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
